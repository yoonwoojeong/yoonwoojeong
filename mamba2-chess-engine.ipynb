{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":14838027,"sourceType":"datasetVersion","datasetId":9489928}],"dockerImageVersionId":31261,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install the latest JAX TPU wheels (forcing a libtpu update)\n!pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n\n!pip install -U chess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:39.787214Z","iopub.execute_input":"2026-02-14T12:22:39.787378Z","iopub.status.idle":"2026-02-14T12:22:42.075239Z","shell.execute_reply.started":"2026-02-14T12:22:39.787362Z","shell.execute_reply":"2026-02-14T12:22:42.074034Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\nRequirement already satisfied: jax[tpu] in /usr/local/lib/python3.12/site-packages (0.9.0.1)\nRequirement already satisfied: jaxlib<=0.9.0.1,>=0.9.0.1 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.9.0.1)\nRequirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.5.4)\nRequirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (2.4.2)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (3.4.0)\nRequirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (1.17.0)\nRequirement already satisfied: libtpu==0.0.34.* in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.0.34)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (2026.1.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: chess in /usr/local/lib/python3.12/site-packages (1.11.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!python -m pip uninstall -y matplotlib\n!python -m pip install -U --no-cache-dir --force-reinstall \"matplotlib>=3.8\" matplotlib-inline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:42.075956Z","iopub.execute_input":"2026-02-14T12:22:42.076157Z","iopub.status.idle":"2026-02-14T12:22:55.263616Z","shell.execute_reply.started":"2026-02-14T12:22:42.076138Z","shell.execute_reply":"2026-02-14T12:22:55.262598Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: matplotlib 3.10.8\nUninstalling matplotlib-3.10.8:\n  Successfully uninstalled matplotlib-3.10.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mCollecting matplotlib>=3.8\n  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\nCollecting matplotlib-inline\n  Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting contourpy>=1.0.1 (from matplotlib>=3.8)\n  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting cycler>=0.10 (from matplotlib>=3.8)\n  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib>=3.8)\n  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib>=3.8)\n  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nCollecting numpy>=1.23 (from matplotlib>=3.8)\n  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nCollecting packaging>=20.0 (from matplotlib>=3.8)\n  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting pillow>=8 (from matplotlib>=3.8)\n  Downloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\nCollecting pyparsing>=3 (from matplotlib>=3.8)\n  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\nCollecting python-dateutil>=2.7 (from matplotlib>=3.8)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting traitlets (from matplotlib-inline)\n  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nCollecting six>=1.5 (from python-dateutil>=2.7->matplotlib>=3.8)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m144.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\nDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\nDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m287.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m272.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-26.0-py3-none-any.whl (74 kB)\nDownloading pillow-12.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m280.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\nDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: traitlets, six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, matplotlib-inline, contourpy, matplotlib\n  Attempting uninstall: traitlets\n    Found existing installation: traitlets 5.14.3\n    Uninstalling traitlets-5.14.3:\n      Successfully uninstalled traitlets-5.14.3\n  Attempting uninstall: six\n    Found existing installation: six 1.17.0\n    Uninstalling six-1.17.0:\n      Successfully uninstalled six-1.17.0\n  Attempting uninstall: pyparsing\n    Found existing installation: pyparsing 3.3.2\n    Uninstalling pyparsing-3.3.2:\n      Successfully uninstalled pyparsing-3.3.2\n  Attempting uninstall: pillow\n    Found existing installation: pillow 12.1.1\n    Uninstalling pillow-12.1.1:\n      Successfully uninstalled pillow-12.1.1\n  Attempting uninstall: packaging\n    Found existing installation: packaging 26.0\n    Uninstalling packaging-26.0:\n      Successfully uninstalled packaging-26.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.4.2\n    Uninstalling numpy-2.4.2:\n      Successfully uninstalled numpy-2.4.2\n  Attempting uninstall: kiwisolver\n    Found existing installation: kiwisolver 1.4.9\n    Uninstalling kiwisolver-1.4.9:\n      Successfully uninstalled kiwisolver-1.4.9\n  Attempting uninstall: fonttools\n    Found existing installation: fonttools 4.61.1\n    Uninstalling fonttools-4.61.1:\n      Successfully uninstalled fonttools-4.61.1\n  Attempting uninstall: cycler\n    Found existing installation: cycler 0.12.1\n    Uninstalling cycler-0.12.1:\n      Successfully uninstalled cycler-0.12.1\n  Attempting uninstall: python-dateutil\n    Found existing installation: python-dateutil 2.9.0.post0\n    Uninstalling python-dateutil-2.9.0.post0:\n      Successfully uninstalled python-dateutil-2.9.0.post0\n  Attempting uninstall: matplotlib-inline\n    Found existing installation: matplotlib-inline 0.2.1\n    Uninstalling matplotlib-inline-0.2.1:\n      Successfully uninstalled matplotlib-inline-0.2.1\n  Attempting uninstall: contourpy\n    Found existing installation: contourpy 1.3.3\n    Uninstalling contourpy-1.3.3:\n      Successfully uninstalled contourpy-1.3.3\nSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 matplotlib-inline-0.2.1 numpy-2.4.2 packaging-26.0 pillow-12.1.1 pyparsing-3.3.2 python-dateutil-2.9.0.post0 six-1.17.0 traitlets-5.14.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nfrom flax.training import train_state\nimport chess\nimport chess.svg\nimport numpy as np\nimport optax\nimport math\nimport time\nfrom einops import rearrange\nfrom IPython.display import display, clear_output, HTML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:55.264197Z","iopub.execute_input":"2026-02-14T12:22:55.264365Z","iopub.status.idle":"2026-02-14T12:22:56.027368Z","shell.execute_reply.started":"2026-02-14T12:22:55.264346Z","shell.execute_reply":"2026-02-14T12:22:56.026579Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==============================================================================\n# 1. OPTIMAL UNI-DIRECTIONAL ARCHITECTURE (COMPUTE-BOUND)\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nfrom einops import rearrange\nimport numpy as np\n\nBATCH_SIZE = 128\nD_MODEL = 256\nN_STATE = 64\nTIMESTEPS = 100\nNUM_CLASSES = 14  # 0 empty, 1..12 pieces, 13 mask\n\nclass UniMambaBlock(nn.Module):\n    d_model: int\n    n_state: int\n    \n    @nn.compact\n    def __call__(self, x, time_emb):\n        B, L, D = x.shape\n        x_fused = x + time_emb[:, jnp.newaxis, :]\n        \n        A_log = self.param('A_log', nn.initializers.normal(0.1), (self.d_model, self.n_state))\n        A = -jnp.exp(A_log)\n        A_inv = 1.0 / (A + 1e-7) \n        \n        B_proj = nn.Dense(self.n_state, dtype=jnp.bfloat16)(x_fused) \n        C_proj = nn.Dense(self.n_state, dtype=jnp.bfloat16)(x_fused)\n        delta_proj = nn.Dense(self.d_model, dtype=jnp.bfloat16)(x_fused) \n        \n        def scan_fn(h, params):\n            b_t, c_t, delta_raw_t, x_t = params\n            delta = nn.softplus(delta_raw_t.astype(jnp.float32))\n            \n            dt_A = jnp.einsum('bd,dn->bdn', delta, A)\n            A_bar = jnp.exp(dt_A)\n            \n            B_bar = jnp.einsum('bdn,dn,bn->bdn', (A_bar - 1.0), A_inv, b_t.astype(jnp.float32))\n            h_new = A_bar * h + jnp.einsum('bdn,bd->bdn', B_bar, x_t.astype(jnp.float32))\n            y_t = jnp.einsum('bdn,bn->bd', h_new, c_t.astype(jnp.float32))\n            return h_new, y_t.astype(jnp.bfloat16)\n\n        Xs_fwd = (\n            rearrange(B_proj, 'b l ... -> l b ...'),\n            rearrange(C_proj, 'b l ... -> l b ...'),\n            rearrange(delta_proj, 'b l ... -> l b ...'),\n            rearrange(x_fused, 'b l ... -> l b ...')\n        )\n        \n        h_init = jnp.zeros((B, self.d_model, self.n_state), dtype=jnp.float32)\n        _, y_f = jax.lax.scan(scan_fn, h_init, Xs_fwd)\n        y_out = rearrange(y_f, 'l b d -> b l d')\n        \n        return nn.LayerNorm(dtype=jnp.bfloat16)(y_out + x)\n\nclass UniMambaChessEngine(nn.Module):\n    @nn.compact\n    def __call__(self, x_t, t, mask_dest=None): \n        x = nn.Embed(NUM_CLASSES, D_MODEL, dtype=jnp.bfloat16)(x_t)\n        \n        indices = jnp.arange(64)\n        rank_emb = nn.Embed(8, D_MODEL, dtype=jnp.bfloat16)(jnp.tile(indices // 8, (x_t.shape[0], 1)))\n        file_emb = nn.Embed(8, D_MODEL, dtype=jnp.bfloat16)(jnp.tile(indices % 8, (x_t.shape[0], 1)))\n        \n        x = x + rank_emb + file_emb\n        x = nn.Dense(D_MODEL, dtype=jnp.bfloat16)(x) \n        \n        t_emb = nn.Embed(TIMESTEPS, D_MODEL, dtype=jnp.bfloat16)(t)\n        Block = nn.remat(UniMambaBlock)\n            \n        for _ in range(4): \n            x = Block(D_MODEL, N_STATE)(x, t_emb)\n            x = nn.gelu(x)\n\n        # -----------------------\n        # Value head (always built)\n        # -----------------------\n        pooled = jnp.mean(x.astype(jnp.float32), axis=1)  # [B, D]\n        v = nn.Dense(128, dtype=jnp.float32, name=\"value_fc\")(pooled)\n        v = nn.gelu(v)\n        v = nn.Dense(1, dtype=jnp.float32, name=\"value_out\")(v)\n        v = jnp.tanh(v).squeeze(-1)  # [B] in [-1, 1]\n\n        # -----------------------\n        # MTM head (same params regardless of branch)\n        # -----------------------\n        mtm_head = nn.Dense(NUM_CLASSES, dtype=jnp.float32, name=\"mtm_head\")\n\n        if mask_dest is not None:\n            dest_vec = jnp.sum(x * mask_dest.astype(jnp.bfloat16), axis=1)  # [B, D]\n            logits = mtm_head(dest_vec)  # [B, 14]\n            return logits, v\n\n        logits = mtm_head(jnp.mean(x.astype(jnp.float32), axis=1))\n        return logits, v\n\ninference_model = UniMambaChessEngine()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.027764Z","iopub.execute_input":"2026-02-14T12:22:56.027983Z","iopub.status.idle":"2026-02-14T12:22:56.038080Z","shell.execute_reply.started":"2026-02-14T12:22:56.027968Z","shell.execute_reply":"2026-02-14T12:22:56.037473Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n# CELL 2: DENSE ALGEBRAIC KERNELS (100% XLA FUSION)\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport optax\nimport numpy as np\n\ndef board_to_tensor(board):\n    x = np.zeros(64, dtype=np.int32)\n    for i in range(64):\n        p = board.piece_at(i)\n        if p: x[i] = p.piece_type + (0 if p.color else 6)\n    return x\n\n@jax.jit\ndef calculate_mtm_energies(frozen_params, candidate_batch, dest_indices, piece_classes):\n    \"\"\"\n    Returns:\n      energies: [N]      = -log P(correct_piece_at_dest)\n      probs:    [N, 14]  = softmax logits\n      values:   [N]      = value head output for candidate states (side-to-move in that candidate)\n    \"\"\"\n    num_candidates = candidate_batch.shape[0]\n    \n    mask_dest = jax.nn.one_hot(dest_indices, 64, dtype=jnp.int32)\n    masked_batch = candidate_batch * (1 - mask_dest) + 13 * mask_dest\n    t_batch = jnp.full((num_candidates,), 1, dtype=jnp.int32)\n    \n    mask_dest_expanded = jnp.expand_dims(mask_dest, -1).astype(jnp.float32)\n    dest_logits, values = inference_model.apply(\n        {'params': frozen_params}, masked_batch, t_batch, mask_dest=mask_dest_expanded\n    )\n    \n    probs = jax.nn.softmax(dest_logits, axis=-1)\n    mask_piece = jax.nn.one_hot(piece_classes, 14, dtype=jnp.float32)\n    actual_piece_probs = jnp.sum(probs * mask_piece, axis=-1)\n    \n    energies = -jnp.log(actual_piece_probs + 1e-7)\n    return energies, probs, values\n\nVALUE_LOSS_WEIGHT = 0.25\n\n@jax.jit\ndef rl_mtm_train_step(state, masked_boards, dest_indices, target_classes, value_targets):\n    \"\"\"\n    Joint supervised step:\n      - MTM: predict moved piece class at destination square\n      - Value: predict game result (coarse target) from side-to-move perspective\n    \"\"\"\n    def loss_fn(params):\n        num_samples = masked_boards.shape[0]\n        t_batch = jnp.full((num_samples,), 1, dtype=jnp.int32)\n        \n        mask_dest = jax.nn.one_hot(dest_indices, 64, dtype=jnp.float32)\n        mask_dest_expanded = jnp.expand_dims(mask_dest, -1)\n        \n        logits, v_pred = inference_model.apply(\n            {'params': params}, masked_boards, t_batch, mask_dest=mask_dest_expanded\n        )\n        \n        # MTM loss\n        target_one_hot = jax.nn.one_hot(target_classes, 14, dtype=jnp.float32)\n        log_probs = jax.nn.log_softmax(logits, axis=-1)\n        mtm_loss = -jnp.sum(target_one_hot * log_probs, axis=-1).mean()\n\n        # Value loss\n        v_loss = optax.huber_loss(v_pred, value_targets).mean()\n\n        preds = jnp.argmax(logits, axis=-1)\n        acc = jnp.mean(preds == target_classes)\n\n        loss = mtm_loss + VALUE_LOSS_WEIGHT * v_loss\n        return loss, (mtm_loss, v_loss, acc)\n\n    (loss, (mtm_loss, v_loss, acc)), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    return state, loss, mtm_loss, v_loss, acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.038593Z","iopub.execute_input":"2026-02-14T12:22:56.038744Z","iopub.status.idle":"2026-02-14T12:22:56.050717Z","shell.execute_reply.started":"2026-02-14T12:22:56.038730Z","shell.execute_reply":"2026-02-14T12:22:56.050080Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ==============================================================================\n# CELL 2B (REPLACE): DONATION + PROFILER ANNOTATIONS (SAFE)\n#   - Do NOT donate arg0 (TrainState). Only donate batch arrays.\n# ==============================================================================\nimport jax\nfrom jax import profiler as jprof\n\n_rl_mtm_train_step_impl = rl_mtm_train_step  # keep original implementation\n\n@jax.jit(donate_argnums=(1, 2, 3, 4))  # ✅ donate only batch inputs, NOT state\ndef rl_mtm_train_step(state, masked_boards, dest_indices, target_classes, value_targets):\n    with jprof.TraceAnnotation(\"train_step\", _r=1):\n        return _rl_mtm_train_step_impl(state, masked_boards, dest_indices, target_classes, value_targets)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.051152Z","iopub.execute_input":"2026-02-14T12:22:56.051300Z","iopub.status.idle":"2026-02-14T12:22:56.059721Z","shell.execute_reply.started":"2026-02-14T12:22:56.051286Z","shell.execute_reply":"2026-02-14T12:22:56.059149Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ==============================================================================\n# 3. MCTS NODE STRUCTURE WITH ALPHA-BETA OVERRIDES (FIXED POV)\n# ==============================================================================\nclass MCTSNode:\n    def __init__(self, state, parent=None, move=None, prior=0.0):\n        self.state = state\n        self.parent = parent\n        self.move = move\n\n        self.prior = float(prior)\n        self.visits = 0\n        self.value_sum = 0.0  # value from perspective of side-to-move at THIS node\n\n        self.children = {}\n        self.is_expanded = False\n\n        # Proven flags from perspective of side-to-move at THIS node\n        self.is_proven_win = False\n        self.is_proven_loss = False\n\n        self.xray_probs = None\n        self.xray_piece = None\n        \n    @property\n    def q_value(self):\n        if self.is_proven_win:\n            return 1.0\n        if self.is_proven_loss:\n            return -1.0\n        return (self.value_sum / self.visits) if self.visits > 0 else 0.0\n\n    def ucb_from_parent(self, c_puct):\n        \"\"\"\n        Selection score from *parent* perspective.\n        Since child.q_value is from child's side-to-move perspective (opponent),\n        parent wants to maximize (-child.q_value).\n        \"\"\"\n        if self.is_proven_loss:\n            # opponent-to-move is proven loss => this move is forced win for parent\n            return float('inf')\n        if self.is_proven_win:\n            # opponent-to-move is proven win => terrible for parent\n            return -float('inf')\n\n        parent_visits = max(1, self.parent.visits if self.parent else 1)\n        q_parent = -self.q_value\n        u = c_puct * self.prior * (math.sqrt(parent_visits) / (1.0 + self.visits))\n        return q_parent + u\n\ndef update_solved(n: MCTSNode):\n    if not n.children:\n        return\n    # If ANY child is proven_loss (for side-to-move in child), current is proven_win\n    if any(ch.is_proven_loss for ch in n.children.values()):\n        n.is_proven_win, n.is_proven_loss = True, False\n        return\n    # If ALL children are proven_win, current is proven_loss\n    if all(ch.is_proven_win for ch in n.children.values()):\n        n.is_proven_win, n.is_proven_loss = False, True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.060115Z","iopub.execute_input":"2026-02-14T12:22:56.060258Z","iopub.status.idle":"2026-02-14T12:22:56.067037Z","shell.execute_reply.started":"2026-02-14T12:22:56.060244Z","shell.execute_reply":"2026-02-14T12:22:56.066464Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ==============================================================================\n# 4. THE OMNISCIENT DASHBOARD (UI VISUALIZER) [FIXED SEMANTICS]\n# ==============================================================================\nPIECE_NAMES = [\"Empty\", \"W_P\", \"W_N\", \"W_B\", \"W_R\", \"W_Q\", \"W_K\", \n               \"B_P\", \"B_N\", \"B_B\", \"B_R\", \"B_Q\", \"B_K\", \"MASK\"]\n\ndef render_dashboard(root, board, phase_title, sim_status, loss_info=\"\"):\n    children = sorted(root.children.values(), key=lambda c: c.visits, reverse=True)\n    fill, arrows = {}, []\n    \n    if children:\n        total_visits = sum(c.visits for c in children) + 1e-9\n        for child in children:\n            opacity = int((child.visits / total_visits) * 255)\n            fill[child.move.to_square] = f\"#0055ff{opacity:02x}\" \n            \n        curr, depth = root, 0\n        while curr.children and depth < 4:\n            kids = list(curr.children.values())\n            forced = [c for c in kids if c.is_proven_loss]  # forced win for parent\n            if forced:\n                best = forced[0]\n            else:\n                safe = [c for c in kids if not c.is_proven_win] or kids\n                best = max(safe, key=lambda c: c.visits)\n            arrows.append(chess.svg.Arrow(best.move.from_square, best.move.to_square, color=\"#28a745\"))\n            curr = best\n            depth += 1\n\n    board_svg = chess.svg.board(\n        board, arrows=arrows, fill=fill, size=400,\n        lastmove=board.peek() if board.move_stack else None\n    )\n    \n    if children:\n        best = children[0]\n        root_q = -best.q_value\n        eval_score = ((root_q + 1) / 2 * 100)\n    else:\n        eval_score = 50.0\n    \n    eval_color = \"green\" if eval_score > 55 else \"red\" if eval_score < 45 else \"black\"\n    \n    html = f\"\"\"\n    <div style='display:flex; gap:20px; font-family:sans-serif; max-width:900px; margin:auto; padding:10px; border:1px solid #ddd; border-radius:8px;'>\n        <div>{board_svg}</div>\n        <div style='flex-grow:1;'>\n            <h2 style='margin-top:0; color:#333;'>{phase_title}</h2>\n            <div style='background:#f8f9fa; padding:10px; border-radius:5px; margin-bottom:10px;'>\n                <b>Status:</b> {sim_status} <br>\n                <b>Engine Eval (root POV):</b> <span style='color: {eval_color}; font-weight: bold;'>{eval_score:.1f}% Win Probability</span>\n                {f\"<br><b>Train Loss:</b> {loss_info}\" if loss_info else \"\"}\n            </div>\n            <h4 style='border-bottom: 1px solid #ccc; padding-bottom: 5px;'>X-Ray Internal Monologue</h4>\n            <div style='max-height: 280px; overflow-y: auto; font-size: 13px;'>\n    \"\"\"\n    \n    for i, c in enumerate(children[:3]):\n        tag = \"\"\n        if c.is_proven_loss:\n            tag = \"<span style='color: green; font-weight: bold;'>[FORCED WIN MOVE]</span>\"\n        elif c.is_proven_win:\n            tag = \"<span style='color: red; font-weight: bold;'>[LOSING MOVE]</span>\"\n\n        html += f\"<div style='margin-bottom: 12px; padding: 8px; border-left: 3px solid #0055ff; background: #fdfdfd;'>\"\n        html += f\"<b>Line {i+1}: {board.san(c.move)}</b> {tag}<br>\"\n        html += f\"<span style='color: #666;'>Visits: {c.visits} | Q(root): {-c.q_value:.2f} | Prior: {c.prior*100:.1f}%</span><br>\"\n        \n        if c.xray_probs is not None:\n            html += f\"<div style='margin-top: 4px; font-family: monospace; font-size: 11px; color: #444;'>\"\n            html += f\"<b>[MASK] Prediction (Target Sq):</b><br>\"\n            top_preds = np.argsort(c.xray_probs)[::-1][:2]\n            for idx in top_preds:\n                mark = \" &lt;-- Actual\" if idx == c.xray_piece else \"\"\n                html += f\"&nbsp;&nbsp;{PIECE_NAMES[idx]}: {c.xray_probs[idx]*100:.1f}%{mark}<br>\"\n            if c.xray_piece not in top_preds:\n                html += f\"&nbsp;&nbsp;... {PIECE_NAMES[c.xray_piece]}: {c.xray_probs[c.xray_piece]*100:.2f}% &lt;-- Actual<br>\"\n            html += \"</div>\"\n        html += \"</div>\"\n        \n    html += \"</div></div></div>\"\n    \n    clear_output(wait=True)\n    display(HTML(html))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.067430Z","iopub.execute_input":"2026-02-14T12:22:56.067580Z","iopub.status.idle":"2026-02-14T12:22:56.077384Z","shell.execute_reply.started":"2026-02-14T12:22:56.067565Z","shell.execute_reply":"2026-02-14T12:22:56.076817Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ==============================================================================\n# 5. CORE MCTS EXECUTION ALGORITHM (FIXED POV + SOFT PRIORS + VALUE HEAD)\n# ==============================================================================\ndef run_mcts(\n    root,\n    params,\n    num_simulations=100,\n    phase_title=\"Engine Analysis\",\n    visualize=False,\n    c_puct=2.0,\n    temp=3.0,           # >1.0 reduces overconfidence\n    prior_mix=0.20,     # mix priors with uniform\n    add_root_noise=True,\n    dirichlet_alpha=0.3,\n    dirichlet_eps=0.25,\n):\n    for i in range(num_simulations):\n        node = root\n        path = [node]\n\n        # 1) Selection (parent POV is handled inside ucb_from_parent)\n        while node.is_expanded and node.children and not (node.is_proven_win or node.is_proven_loss):\n            node = max(node.children.values(), key=lambda c: c.ucb_from_parent(c_puct))\n            path.append(node)\n\n        # 2) Terminal handling\n        if node.is_proven_win:\n            leaf_value = 1.0\n        elif node.is_proven_loss:\n            leaf_value = -1.0\n        elif node.state.is_game_over():\n            outcome = node.state.outcome()\n            if outcome.winner is None:\n                leaf_value = 0.0\n            else:\n                leaf_value = 1.0 if outcome.winner == node.state.turn else -1.0\n            if leaf_value == 1.0:\n                node.is_proven_win = True\n            elif leaf_value == -1.0:\n                node.is_proven_loss = True\n        else:\n            # 3) Expansion using MTM prior + VALUE HEAD evaluation\n            moves = list(node.state.legal_moves)\n            candidates, dest_indices, piece_classes = [], [], []\n            \n            for m in moves:\n                node.state.push(m)\n                candidates.append(board_to_tensor(node.state))\n                dest_indices.append(m.to_square)\n                p = node.state.piece_at(m.to_square)\n                piece_classes.append(p.piece_type + (0 if p.color else 6))\n                node.state.pop()\n                \n            if candidates:\n                energies, full_probs, child_values = calculate_mtm_energies(\n                    params,\n                    jnp.array(candidates, dtype=jnp.int32),\n                    jnp.array(dest_indices, dtype=jnp.int32),\n                    jnp.array(piece_classes, dtype=jnp.int32),\n                )\n                energies = np.array(energies)\n                full_probs = np.array(full_probs)\n                child_values = np.array(child_values)  # from child POV (opponent-to-move)\n\n                # Soft priors: exp(-E/temp), normalize, then mix with uniform\n                logits = -energies / float(temp)\n                logits = logits - np.max(logits)\n                priors = np.exp(logits)\n                priors = priors / (np.sum(priors) + 1e-12)\n                priors = (1.0 - prior_mix) * priors + prior_mix * (1.0 / len(priors))\n\n                # Root Dirichlet noise to avoid tunnel vision\n                if add_root_noise and node is root:\n                    noise = np.random.dirichlet([dirichlet_alpha] * len(priors))\n                    priors = (1.0 - dirichlet_eps) * priors + dirichlet_eps * noise\n\n                for idx, (m, p) in enumerate(zip(moves, priors)):\n                    new_board = node.state.copy()\n                    new_board.push(m)\n                    child = MCTSNode(new_board, parent=node, move=m, prior=float(p))\n                    child.xray_probs = full_probs[idx]\n                    child.xray_piece = piece_classes[idx]\n                    node.children[m] = child\n\n                node.is_expanded = True\n\n                # Leaf value from node POV:\n                # child_values are from opponent POV => node POV is negative of that\n                leaf_value = float(-np.sum(priors * child_values))\n                leaf_value = float(np.clip(leaf_value, -1.0, 1.0))\n            else:\n                leaf_value = 0.0\n\n        # 4) Backprop with sign flip + solved propagation\n        value = leaf_value\n        for n in reversed(path):\n            n.visits += 1\n            n.value_sum += value\n            update_solved(n)\n            value = -value\n\n        # 5) UI Hook\n        if visualize and i % 10 == 0:\n            render_dashboard(root, root.state, phase_title, f\"Simulating {i}/{num_simulations}...\")\n\n    if visualize:\n        render_dashboard(root, root.state, phase_title, \"Analysis Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.077909Z","iopub.execute_input":"2026-02-14T12:22:56.078075Z","iopub.status.idle":"2026-02-14T12:22:56.087477Z","shell.execute_reply.started":"2026-02-14T12:22:56.078043Z","shell.execute_reply":"2026-02-14T12:22:56.086850Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ==============================================================================\n# CELL 5.5 (REPLACE): EXPERT DATASET LOADER (MULTI-PGN, POST-MOVE MTM, VALUE POV)\n#   - Creates samples from the board *after* each move (matches calculate_mtm_energies)\n#   - Masks move.to_square in that post-move board\n#   - Target class is the actual piece now occupying that square (handles promotion)\n#   - Value target matches the side-to-move of the post-move board\n# ==============================================================================\nimport os\nimport numpy as np\nimport jax.numpy as jnp\nimport chess\nimport chess.pgn\n\ndef _result_to_winner(result_str: str):\n    if result_str == \"1-0\": return chess.WHITE\n    if result_str == \"0-1\": return chess.BLACK\n    return None\n\ndef make_multi_pgn_dataloader(\n    pgn_files,\n    batches_per_epoch: int,\n    batch_size: int = 128,\n    seed: int = 0,\n    shuffle_files_each_epoch: bool = True,\n):\n    missing = [p for p in pgn_files if not os.path.exists(p)]\n    if missing:\n        print(\"❌ Missing PGN files:\")\n        for m in missing: print(\" -\", m)\n        raise FileNotFoundError(\"Some PGN files are missing.\")\n\n    def dataloader_factory(epoch: int = 0):\n        order = list(pgn_files)\n        if shuffle_files_each_epoch:\n            rng = np.random.default_rng(seed + epoch)\n            rng.shuffle(order)\n\n        masked_boards, dest_indices, target_classes, value_targets = [], [], [], []\n        yielded = 0\n\n        for path in order:\n            with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as pgn:\n                while yielded < batches_per_epoch:\n                    game = chess.pgn.read_game(pgn)\n                    if game is None:\n                        break\n\n                    winner = _result_to_winner(game.headers.get(\"Result\", \"*\"))\n                    board = game.board()\n\n                    for move in game.mainline_moves():\n                        # --- advance to post-move board (this is what MCTS evaluates) ---\n                        board.push(move)\n\n                        dest_sq = move.to_square\n                        piece = board.piece_at(dest_sq)\n                        if piece is None:\n                            # should not happen, but guard anyway\n                            continue\n\n                        piece_class = piece.piece_type + (0 if piece.color else 6)\n\n                        # value label from POV of *side-to-move in this post-move state*\n                        if winner is None:\n                            v_t = 0.0\n                        else:\n                            v_t = 1.0 if board.turn == winner else -1.0\n\n                        bt = board_to_tensor(board)\n                        bt[dest_sq] = 13  # MASK the destination in the post-move board\n\n                        masked_boards.append(bt)\n                        dest_indices.append(dest_sq)\n                        target_classes.append(piece_class)\n                        value_targets.append(v_t)\n\n                        if len(masked_boards) == batch_size:\n                            yield (\n                                jnp.array(masked_boards, dtype=jnp.int32),\n                                jnp.array(dest_indices, dtype=jnp.int32),\n                                jnp.array(target_classes, dtype=jnp.int32),\n                                jnp.array(value_targets, dtype=jnp.float32),\n                            )\n                            yielded += 1\n                            masked_boards, dest_indices, target_classes, value_targets = [], [], [], []\n                            if yielded >= batches_per_epoch:\n                                return\n\n        if yielded < batches_per_epoch:\n            print(f\"⚠️ Epoch ended early: yielded {yielded}/{batches_per_epoch} batches.\")\n\n    return dataloader_factory\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.087928Z","iopub.execute_input":"2026-02-14T12:22:56.088098Z","iopub.status.idle":"2026-02-14T12:22:56.106460Z","shell.execute_reply.started":"2026-02-14T12:22:56.088083Z","shell.execute_reply":"2026-02-14T12:22:56.105836Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ==============================================================================\n# CELL 6 (REPLACE): TRAINING + HW/SW PROFILING + PLOTS (FIXED WARMUP)\n# ==============================================================================\nimport time\nimport re\nimport os\nimport numpy as np\nimport jax\nimport jax.numpy as jnp\nfrom jax import profiler as jprof\nfrom IPython.display import clear_output, display, HTML\n\nMAX_TRAIN_BATCH = 128\n\ndef _try_device_memory_stats():\n    try:\n        return jax.devices()[0].memory_stats()\n    except Exception as e1:\n        try:\n            backend = jax.lib.xla_bridge.get_backend()\n            return backend.memory_stats()\n        except Exception as e2:\n            return {\"unavailable\": True, \"err1\": repr(e1), \"err2\": repr(e2)}\n\ndef _hlo_memory_space_report(compiled):\n    try:\n        hlo = compiled.compiler_ir(dialect=\"hlo\").as_text()\n        ms = re.findall(r\"memory_space=(\\d+)\", hlo)\n        counts = {}\n        for x in ms:\n            k = int(x)\n            counts[k] = counts.get(k, 0) + 1\n        async_copies = len(re.findall(r\"copy-start|copy-done|async-copy\", hlo))\n        return {\"memory_space_counts\": counts, \"async_copy_ops\": async_copies}\n    except Exception as e:\n        return {\"error\": repr(e)}\n\ndef _xla_mem_analysis(compiled):\n    try:\n        mem = compiled.memory_analysis()\n        return {\n            \"temp_mb\": mem.temp_size_in_bytes / (1024**2),\n            \"args_mb\": mem.argument_size_in_bytes / (1024**2),\n            \"out_mb\":  mem.output_size_in_bytes / (1024**2),\n        }\n    except Exception as e:\n        return {\"error\": repr(e)}\n\ndef _safe_plots(history):\n    try:\n        import matplotlib.pyplot as plt\n        plt.figure()\n        plt.plot(history[\"loss_epoch\"], label=\"loss\")\n        plt.plot(history[\"mtm_loss_epoch\"], label=\"mtm_loss\")\n        plt.plot(history[\"v_loss_epoch\"], label=\"v_loss\")\n        plt.legend(); plt.title(\"Loss per epoch\"); plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.show()\n\n        plt.figure()\n        plt.plot(history[\"acc_epoch\"], label=\"MTM Acc (%)\")\n        plt.legend(); plt.title(\"Accuracy per epoch\"); plt.xlabel(\"epoch\"); plt.ylabel(\"%\"); plt.show()\n\n        plt.figure()\n        plt.plot(history[\"sps_epoch\"], label=\"SPS\")\n        plt.legend(); plt.title(\"Throughput per epoch\"); plt.xlabel(\"epoch\"); plt.ylabel(\"samples/s\"); plt.show()\n\n        plt.figure()\n        plt.plot(history[\"p50_ms_epoch\"], label=\"p50 ms\")\n        plt.plot(history[\"p90_ms_epoch\"], label=\"p90 ms\")\n        plt.plot(history[\"p99_ms_epoch\"], label=\"p99 ms\")\n        plt.legend(); plt.title(\"Device step latency (ms)\"); plt.xlabel(\"epoch\"); plt.ylabel(\"ms\"); plt.show()\n    except Exception as e:\n        print(\"⚠️ matplotlib unavailable/broken; skipping plots.\")\n        print(\"Reason:\", repr(e))\n\ndef _render_perf_panel(ep, epochs, step, steps_in_epoch, metrics, hw, memstats):\n    html = f\"\"\"\n    <div style=\"font-family:system-ui, -apple-system, Segoe UI, Roboto, sans-serif; padding:12px; border:1px solid #ddd; border-radius:10px;\">\n      <h3 style=\"margin:0 0 8px 0;\">Training Perf (SW + HW)</h3>\n      <div style=\"display:grid; grid-template-columns: 1fr 1fr; gap:12px;\">\n        <div style=\"background:#f6f8fa; border-radius:10px; padding:10px;\">\n          <div><b>Epoch</b> {ep}/{epochs} &nbsp; <b>Step</b> {step}/{steps_in_epoch}</div>\n          <div style=\"margin-top:6px;\">\n            <b>Loss</b> {metrics[\"loss\"]:.4f} &nbsp;\n            <b>MTM</b> {metrics[\"mtm_loss\"]:.4f} &nbsp;\n            <b>V</b> {metrics[\"v_loss\"]:.4f} &nbsp;\n            <b>Acc</b> {metrics[\"acc\"]:.1f}%\n          </div>\n          <div style=\"margin-top:6px;\">\n            <b>SPS</b> {metrics[\"sps\"]:,.0f} &nbsp;\n            <b>Fetch</b> {metrics[\"batch_fetch_ms\"]:.2f}ms &nbsp;\n            <b>Device</b> {metrics[\"device_ms\"]:.2f}ms &nbsp;\n            <b>E2E</b> {metrics[\"e2e_ms\"]:.2f}ms\n          </div>\n          <div style=\"margin-top:6px;\">\n            <b>Latency p50/p90/p99</b>: {metrics[\"p50_ms\"]:.2f}/{metrics[\"p90_ms\"]:.2f}/{metrics[\"p99_ms\"]:.2f} ms\n          </div>\n        </div>\n        <div style=\"background:#f6f8fa; border-radius:10px; padding:10px;\">\n          <div><b>Backend</b>: {hw[\"backend\"]}</div>\n          <div style=\"margin-top:6px;\"><b>Devices</b>:<br><span style=\"font-size:12px;\">{hw[\"devices\"]}</span></div>\n          <div style=\"margin-top:6px;\"><b>Compile</b>: {hw[\"compile_s\"]:.2f}s</div>\n          <div style=\"margin-top:6px;\"><b>XLA Mem (MB)</b>: temp={hw[\"xla_temp_mb\"]:.1f} args={hw[\"xla_args_mb\"]:.1f} out={hw[\"xla_out_mb\"]:.1f}</div>\n          <div style=\"margin-top:6px;\"><b>HLO memory_space</b>: {hw[\"hlo_ms\"]}</div>\n          <div style=\"margin-top:6px;\"><b>Async copies</b>: {hw[\"hlo_async\"]}</div>\n        </div>\n      </div>\n      <div style=\"margin-top:10px; background:#fff; border:1px solid #eee; border-radius:10px; padding:10px;\">\n        <b>Device memory stats</b> (if available):<br>\n        <pre style=\"margin:6px 0 0 0; white-space:pre-wrap; font-size:12px;\">{memstats}</pre>\n      </div>\n    </div>\n    \"\"\"\n    clear_output(wait=True)\n    display(HTML(html))\n\ndef train_supervised_phase(\n    train_state_obj,\n    dataloader_factory,\n    epochs=5,\n    batches_per_epoch=300,\n    ui_every=10,\n    trace_dir=None,\n    trace_steps=30,\n):\n    dummy_boards = jnp.zeros((MAX_TRAIN_BATCH, 64), dtype=jnp.int32)\n    dummy_dests  = jnp.zeros((MAX_TRAIN_BATCH,), dtype=jnp.int32)\n    dummy_targs  = jnp.zeros((MAX_TRAIN_BATCH,), dtype=jnp.int32)\n    dummy_vals   = jnp.zeros((MAX_TRAIN_BATCH,), dtype=jnp.float32)\n\n    compile_t0 = time.time()\n    compiled = rl_mtm_train_step.lower(train_state_obj, dummy_boards, dummy_dests, dummy_targs, dummy_vals).compile()\n    compile_s = time.time() - compile_t0\n\n    xla_mem = _xla_mem_analysis(compiled)\n    hlo_rep = _hlo_memory_space_report(compiled)\n\n    devs = jax.devices()\n    backend = jax.default_backend()\n    dev_str = \", \".join([f\"{d.platform}:{getattr(d, 'device_kind', 'device')}\" for d in devs])\n\n    hw = {\n        \"backend\": backend,\n        \"devices\": dev_str,\n        \"compile_s\": float(compile_s),\n        \"xla_temp_mb\": float(xla_mem.get(\"temp_mb\", float(\"nan\"))),\n        \"xla_args_mb\": float(xla_mem.get(\"args_mb\", float(\"nan\"))),\n        \"xla_out_mb\":  float(xla_mem.get(\"out_mb\", float(\"nan\"))),\n        \"hlo_ms\": str(hlo_rep.get(\"memory_space_counts\", {})),\n        \"hlo_async\": int(hlo_rep.get(\"async_copy_ops\", 0)) if \"async_copy_ops\" in hlo_rep else -1,\n    }\n\n    # ✅ warmup must rebind state (safe even without donating state)\n    train_state_obj, _, _, _, _ = rl_mtm_train_step(\n        train_state_obj, dummy_boards, dummy_dests, dummy_targs, dummy_vals\n    )\n    jax.block_until_ready(train_state_obj.params)\n\n    tracing = False\n    traced = 0\n    if trace_dir:\n        os.makedirs(trace_dir, exist_ok=True)\n        jprof.start_trace(trace_dir)\n        tracing = True\n\n    history = {\n        \"epoch\": [],\n        \"loss_epoch\": [], \"mtm_loss_epoch\": [], \"v_loss_epoch\": [], \"acc_epoch\": [],\n        \"sps_epoch\": [],\n        \"p50_ms_epoch\": [], \"p90_ms_epoch\": [], \"p99_ms_epoch\": [],\n        \"epoch_time_s\": [],\n        \"hardware\": hw,\n    }\n\n    for ep in range(1, epochs + 1):\n        loss_list, mtm_list, v_list, acc_list = [], [], [], []\n        device_ms_list = []\n\n        epoch_t0 = time.time()\n        step = 0\n\n        dl = dataloader_factory(ep - 1)\n        while step < batches_per_epoch:\n            step += 1\n\n            t_fetch0 = time.time()\n            try:\n                batch = next(dl)\n            except StopIteration:\n                break\n            t_fetch1 = time.time()\n\n            m_b, d_i, t_c, v_t = batch\n\n            t_dev0 = time.time()\n            train_state_obj, loss, mtm_loss, v_loss, acc = rl_mtm_train_step(train_state_obj, m_b, d_i, t_c, v_t)\n            jax.block_until_ready(train_state_obj.params)\n            t_dev1 = time.time()\n\n            fetch_ms = (t_fetch1 - t_fetch0) * 1000.0\n            device_ms = (t_dev1 - t_dev0) * 1000.0\n            e2e_ms = (t_dev1 - t_fetch0) * 1000.0\n            device_ms_list.append(device_ms)\n\n            loss_f = float(loss); mtm_f = float(mtm_loss); v_f = float(v_loss); acc_f = float(acc) * 100.0\n            loss_list.append(loss_f); mtm_list.append(mtm_f); v_list.append(v_f); acc_list.append(acc_f)\n\n            if tracing:\n                traced += 1\n                if traced >= trace_steps:\n                    jprof.stop_trace()\n                    tracing = False\n\n            if step % ui_every == 0:\n                recent = np.array(device_ms_list[-min(200, len(device_ms_list)):], dtype=np.float32)\n                p50 = float(np.percentile(recent, 50))\n                p90 = float(np.percentile(recent, 90))\n                p99 = float(np.percentile(recent, 99))\n                sps = MAX_TRAIN_BATCH / max(1e-9, (device_ms / 1000.0))\n                memstats = _try_device_memory_stats()\n\n                _render_perf_panel(\n                    ep, epochs, step, batches_per_epoch,\n                    metrics={\n                        \"loss\": loss_f, \"mtm_loss\": mtm_f, \"v_loss\": v_f, \"acc\": acc_f,\n                        \"sps\": float(sps),\n                        \"batch_fetch_ms\": float(fetch_ms),\n                        \"device_ms\": float(device_ms),\n                        \"e2e_ms\": float(e2e_ms),\n                        \"p50_ms\": p50, \"p90_ms\": p90, \"p99_ms\": p99,\n                    },\n                    hw=hw,\n                    memstats=str(memstats)\n                )\n\n        epoch_s = time.time() - epoch_t0\n        if not loss_list:\n            break\n\n        device_recent = np.array(device_ms_list, dtype=np.float32)\n        history[\"epoch\"].append(ep)\n        history[\"loss_epoch\"].append(float(np.mean(loss_list)))\n        history[\"mtm_loss_epoch\"].append(float(np.mean(mtm_list)))\n        history[\"v_loss_epoch\"].append(float(np.mean(v_list)))\n        history[\"acc_epoch\"].append(float(np.mean(acc_list)))\n        history[\"sps_epoch\"].append(float((len(loss_list) * MAX_TRAIN_BATCH) / max(1e-9, epoch_s)))\n        history[\"p50_ms_epoch\"].append(float(np.percentile(device_recent, 50)))\n        history[\"p90_ms_epoch\"].append(float(np.percentile(device_recent, 90)))\n        history[\"p99_ms_epoch\"].append(float(np.percentile(device_recent, 99)))\n        history[\"epoch_time_s\"].append(float(epoch_s))\n\n    clear_output(wait=True)\n    print(\"✅ Training complete.\")\n    print(\"Hardware snapshot:\", history[\"hardware\"])\n    if trace_dir:\n        print(f\"✅ Trace saved to: {trace_dir}\")\n    _safe_plots(history)\n    return train_state_obj, history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.106908Z","iopub.execute_input":"2026-02-14T12:22:56.107067Z","iopub.status.idle":"2026-02-14T12:22:56.124880Z","shell.execute_reply.started":"2026-02-14T12:22:56.107040Z","shell.execute_reply":"2026-02-14T12:22:56.124289Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ==============================================================================\n# CELL (ADD): INTERACTIVE PLAY LOOP (RESTORES play_interactive)\n# ==============================================================================\nimport chess\n\ndef _safe_render(root, board, title, status):\n    # If you have the dashboard cell, use it; otherwise print text board.\n    if \"render_dashboard\" in globals():\n        render_dashboard(root, board, title, status)\n    else:\n        print(title, \"-\", status)\n        print(board)\n\ndef play_interactive(params, engine_plays_black=True, sims_per_move=60):\n    \"\"\"\n    Interactive match vs engine.\n    - engine_plays_black=True  -> Human plays White, engine plays Black (default)\n    - sims_per_move controls MCTS budget\n    \"\"\"\n    board = chess.Board()\n    root = MCTSNode(board.copy())\n\n    while not board.is_game_over():\n        engine_to_move = (board.turn == chess.BLACK) if engine_plays_black else (board.turn == chess.WHITE)\n\n        if not engine_to_move:\n            _safe_render(root, board, \"Interactive Match\", \"Waiting for Human Input...\")\n            while True:\n                try:\n                    move_input = input(\"Your Move (SAN, e.g., e4, Nf3, O-O) or 'quit': \").strip()\n                    if move_input.lower() in [\"quit\", \"exit\", \"resign\"]:\n                        print(\"Game Aborted.\")\n                        return\n\n                    mv = board.parse_san(move_input)\n                    board.push(mv)\n\n                    # Sync/advance root if possible\n                    if root.children and mv in root.children:\n                        root = root.children[mv]\n                        root.parent = None\n                    else:\n                        root = MCTSNode(board.copy())\n                    break\n                except Exception as e:\n                    print(\"Invalid move. Try again. Error:\", e)\n        else:\n            # Engine move\n            _safe_render(root, board, \"Interactive Match\", f\"Engine thinking... ({sims_per_move} sims)\")\n            run_mcts(root, params, num_simulations=sims_per_move, phase_title=\"Interactive Match\", visualize=(\"render_dashboard\" in globals()))\n\n            if not root.children:\n                print(\"Engine has no moves (resign/stalemate).\")\n                break\n\n            # Prefer forced win if exists: child is_proven_loss => win for parent\n            forced = [c for c in root.children.values() if getattr(c, \"is_proven_loss\", False)]\n            if forced:\n                best = forced[0]\n            else:\n                # Avoid known-losing moves if possible\n                safe = [c for c in root.children.values() if not getattr(c, \"is_proven_win\", False)]\n                if not safe:\n                    safe = list(root.children.values())\n                best = max(safe, key=lambda c: c.visits)\n\n            board.push(best.move)\n            root = best\n            root.parent = None\n\n    _safe_render(root, board, \"Match Finished\", f\"Result: {board.result()}\")\n    print(\"Game Over:\", board.result())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.125309Z","iopub.execute_input":"2026-02-14T12:22:56.125453Z","iopub.status.idle":"2026-02-14T12:22:56.135860Z","shell.execute_reply.started":"2026-02-14T12:22:56.125439Z","shell.execute_reply":"2026-02-14T12:22:56.135246Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ==============================================================================\n# CELL (ADD): KAGGLE/JUPYTER FRIENDLY PLAY UI (ipywidgets)\n#   - No input() needed\n#   - Type SAN move (e.g., e4, Nf3, O-O) and click Submit\n# ==============================================================================\nimport chess\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\ndef play_with_widgets(params, engine_plays_black=True, sims_per_move=60):\n    # Persistent game state inside closure\n    board = chess.Board()\n    root = MCTSNode(board.copy())\n\n    # UI elements\n    move_box = widgets.Text(\n        value=\"\",\n        placeholder=\"Enter SAN move (e.g., e4, Nf3, O-O)\",\n        description=\"Your move:\",\n        layout=widgets.Layout(width=\"420px\"),\n    )\n    submit_btn = widgets.Button(description=\"Submit\", button_style=\"success\")\n    reset_btn = widgets.Button(description=\"Reset\", button_style=\"warning\")\n    status = widgets.HTML(value=\"\")\n    out = widgets.Output()\n\n    def render(title, msg):\n        # Prefer your dashboard if it exists; otherwise just print board\n        if \"render_dashboard\" in globals():\n            render_dashboard(root, board, title, msg)\n        else:\n            with out:\n                clear_output(wait=True)\n                print(title, \"-\", msg)\n                print(board)\n\n    def sync_root_after_move(mv):\n        nonlocal root\n        if root.children and mv in root.children:\n            root = root.children[mv]\n            root.parent = None\n        else:\n            root = MCTSNode(board.copy())\n\n    def engine_move_if_needed():\n        nonlocal root\n        if board.is_game_over():\n            return\n\n        engine_to_move = (board.turn == chess.BLACK) if engine_plays_black else (board.turn == chess.WHITE)\n        if not engine_to_move:\n            return\n\n        render(\"Interactive Match\", f\"Engine thinking... ({sims_per_move} sims)\")\n        run_mcts(root, params, num_simulations=sims_per_move, phase_title=\"Interactive Match\",\n                 visualize=(\"render_dashboard\" in globals()))\n\n        if not root.children:\n            status.value = \"<b>Engine has no moves.</b>\"\n            return\n\n        # Prefer forced win move if exists: child is_proven_loss => win for parent\n        forced = [c for c in root.children.values() if getattr(c, \"is_proven_loss\", False)]\n        if forced:\n            best = forced[0]\n        else:\n            safe = [c for c in root.children.values() if not getattr(c, \"is_proven_win\", False)]\n            if not safe:\n                safe = list(root.children.values())\n            best = max(safe, key=lambda c: c.visits)\n\n        board.push(best.move)\n        root = best\n        root.parent = None\n\n    def on_submit(_):\n        nonlocal root\n        if board.is_game_over():\n            status.value = f\"<b>Game over:</b> {board.result()}\"\n            return\n\n        txt = move_box.value.strip()\n        if not txt:\n            status.value = \"<b>Please enter a SAN move.</b>\"\n            return\n\n        try:\n            mv = board.parse_san(txt)\n            board.push(mv)\n            sync_root_after_move(mv)\n            move_box.value = \"\"\n            status.value = f\"✅ Played: <b>{txt}</b>\"\n\n            # Engine reply\n            engine_move_if_needed()\n\n            if board.is_game_over():\n                status.value += f\"<br><b>Game over:</b> {board.result()}\"\n\n            render(\"Interactive Match\", \"Your turn.\" if ((board.turn == chess.WHITE) == (not engine_plays_black)) else \"Engine turn.\")\n        except Exception as e:\n            status.value = f\"❌ Invalid move: <b>{txt}</b><br><span style='font-size:12px'>{e}</span>\"\n\n    def on_reset(_):\n        nonlocal board, root\n        board = chess.Board()\n        root = MCTSNode(board.copy())\n        move_box.value = \"\"\n        status.value = \"Reset done.\"\n        render(\"Interactive Match\", \"New game. Your turn.\")\n\n    submit_btn.on_click(on_submit)\n    reset_btn.on_click(on_reset)\n\n    # Initial render\n    render(\"Interactive Match\", \"New game. Your turn.\")\n    display(widgets.HBox([move_box, submit_btn, reset_btn]))\n    display(status)\n    display(out)\n\n# Usage:\n# play_with_widgets(master_state.params, engine_plays_black=True, sims_per_move=60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.136283Z","iopub.execute_input":"2026-02-14T12:22:56.136428Z","iopub.status.idle":"2026-02-14T12:22:56.145908Z","shell.execute_reply.started":"2026-02-14T12:22:56.136414Z","shell.execute_reply":"2026-02-14T12:22:56.145316Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# ==============================================================================\n# CELL 7: EXECUTION & LAUNCH (MULTI-DB TRAINING + PERF PLOTS)\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport optax\nfrom flax.training import train_state\nimport chess\n\n# 1) Put your 7 Kaggle PGN paths here:\nPGN_FILES = [\n    # Example (replace with your real Kaggle input paths):\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games.pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (1).pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (2).pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (3).pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (4).pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (5).pgn\",\n    \"/kaggle/input/datasets/yonnwoojeong/master-games/master_games (6).pgn\",\n]\n\nBATCHES_PER_EPOCH = 50   # pick a number (e.g., 200~2000). Controls epoch length.\nEPOCHS = 50\n\n# Build dataloader factory (epoch-aware)\ndataloader_factory = make_multi_pgn_dataloader(\n    PGN_FILES,\n    batches_per_epoch=BATCHES_PER_EPOCH,\n    batch_size=MAX_TRAIN_BATCH,\n    seed=42,\n    shuffle_files_each_epoch=True,\n)\n\n# --- model init (ensure value head + mtm head params exist) ---\ntry:\n    _ = master_state.params\n    print(\"✅ Loaded existing TrainState with weights.\")\nexcept NameError:\n    print(\"⚠️ No existing weights found. Initializing fresh Uni-Mamba model...\")\n    key = jax.random.PRNGKey(42)\n    dummy_x = jnp.zeros((1, 64), dtype=jnp.int32)\n    dummy_t = jnp.zeros((1,), dtype=jnp.int32)\n    dummy_mask = jnp.zeros((1, 64, 1), dtype=jnp.float32).at[:, 0, 0].set(1.0)\n\n    params = inference_model.init(key, dummy_x, dummy_t, mask_dest=dummy_mask)['params']\n    master_state = train_state.TrainState.create(\n        apply_fn=inference_model.apply,\n        params=params,\n        tx=optax.adamw(learning_rate=3e-4),\n    )\n    print(\"✅ Model initialized.\")\n\n# --- train + plot ---\nmaster_state, history = train_supervised_phase(\n    master_state,\n    dataloader_factory=dataloader_factory,\n    epochs=EPOCHS,\n    batches_per_epoch=BATCHES_PER_EPOCH,\n    ui_every=10,\n)\n\n# --- play ---\nplay_interactive(master_state.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T12:22:56.146297Z","iopub.execute_input":"2026-02-14T12:22:56.146443Z"}},"outputs":[{"name":"stdout","text":"⚠️ No existing weights found. Initializing fresh Uni-Mamba model...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1771071776.211944   32641 common_lib.cc:650] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:238\n","output_type":"stream"},{"name":"stdout","text":"✅ Model initialized.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/interpreters/mlir.py:1274: UserWarning: Some donated buffers were not usable: int32[128,64].\nSee an explanation at https://docs.jax.dev/en/latest/faq.html#buffer-donation.\n  warnings.warn(\"Some donated buffers were not usable:\"\n","output_type":"stream"}],"execution_count":null}]}