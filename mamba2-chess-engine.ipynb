{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":14834530,"sourceType":"datasetVersion","datasetId":9487489}],"dockerImageVersionId":31261,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install the latest JAX TPU wheels (forcing a libtpu update)\n!pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n\n!pip install -U chess","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2026-02-14T09:47:55.759933Z","shell.execute_reply.started":"2026-02-14T09:47:53.430224Z","shell.execute_reply":"2026-02-14T09:47:55.758740Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://storage.googleapis.com/jax-releases/libtpu_releases.html\nRequirement already satisfied: jax[tpu] in /usr/local/lib/python3.12/site-packages (0.9.0.1)\nRequirement already satisfied: jaxlib<=0.9.0.1,>=0.9.0.1 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.9.0.1)\nRequirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.5.4)\nRequirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (2.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (3.4.0)\nRequirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (1.17.0)\nRequirement already satisfied: libtpu==0.0.34.* in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (0.0.34)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from jax[tpu]) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->jax[tpu]) (2026.1.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: chess in /usr/local/lib/python3.12/site-packages (1.11.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nfrom flax.training import train_state\nimport chess\nimport chess.svg\nimport numpy as np\nimport optax\nimport math\nimport time\nfrom einops import rearrange\nfrom IPython.display import display, clear_output, HTML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:55.760682Z","iopub.execute_input":"2026-02-14T09:47:55.760852Z","iopub.status.idle":"2026-02-14T09:47:56.417193Z","shell.execute_reply.started":"2026-02-14T09:47:55.760832Z","shell.execute_reply":"2026-02-14T09:47:56.416305Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/jax/_src/cloud_tpu_init.py:93: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ==============================================================================\n# 1. OPTIMAL UNI-DIRECTIONAL ARCHITECTURE (COMPUTE-BOUND)\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport flax.linen as nn\nfrom einops import rearrange\nimport numpy as np\n\nBATCH_SIZE = 128\nD_MODEL = 256\nN_STATE = 64\nTIMESTEPS = 100\nNUM_CLASSES = 14\n\nclass UniMambaBlock(nn.Module):\n    d_model: int\n    n_state: int\n    \n    @nn.compact\n    def __call__(self, x, time_emb):\n        B, L, D = x.shape\n        x_fused = x + time_emb[:, jnp.newaxis, :]\n        \n        A_log = self.param('A_log', nn.initializers.normal(0.1), (self.d_model, self.n_state))\n        A = -jnp.exp(A_log)\n        A_inv = 1.0 / (A + 1e-7) \n        \n        # Native BFloat16 Projections\n        B_proj = nn.Dense(self.n_state, dtype=jnp.bfloat16)(x_fused) \n        C_proj = nn.Dense(self.n_state, dtype=jnp.bfloat16)(x_fused)\n        delta_proj = nn.Dense(self.d_model, dtype=jnp.bfloat16)(x_fused) \n        \n        def scan_fn(h, params):\n            b_t, c_t, delta_raw_t, x_t = params\n            delta = nn.softplus(delta_raw_t.astype(jnp.float32))\n            \n            dt_A = jnp.einsum('bd,dn->bdn', delta, A)\n            A_bar = jnp.exp(dt_A)\n            \n            B_bar = jnp.einsum('bdn,dn,bn->bdn', (A_bar - 1.0), A_inv, b_t.astype(jnp.float32))\n            h_new = A_bar * h + jnp.einsum('bdn,bd->bdn', B_bar, x_t.astype(jnp.float32))\n            y_t = jnp.einsum('bdn,bn->bd', h_new, c_t.astype(jnp.float32))\n            \n            return h_new, y_t.astype(jnp.bfloat16)\n\n        Xs_fwd = (\n            rearrange(B_proj, 'b l ... -> l b ...'),\n            rearrange(C_proj, 'b l ... -> l b ...'),\n            rearrange(delta_proj, 'b l ... -> l b ...'),\n            rearrange(x_fused, 'b l ... -> l b ...')\n        )\n        \n        # 8.38 MB Hidden State -> Fits safely in 16MB SRAM\n        h_init = jnp.zeros((B, self.d_model, self.n_state), dtype=jnp.float32)\n        \n        _, y_f = jax.lax.scan(scan_fn, h_init, Xs_fwd)\n        y_out = rearrange(y_f, 'l b d -> b l d')\n        \n        return nn.LayerNorm(dtype=jnp.bfloat16)(y_out + x)\n\nclass UniMambaChessEngine(nn.Module):\n    @nn.compact\n    def __call__(self, x_t, t, mask_dest=None): \n        x = nn.Embed(NUM_CLASSES, D_MODEL, dtype=jnp.bfloat16)(x_t)\n        \n        indices = jnp.arange(64)\n        rank_emb = nn.Embed(8, D_MODEL, dtype=jnp.bfloat16)(jnp.tile(indices // 8, (x_t.shape[0], 1)))\n        file_emb = nn.Embed(8, D_MODEL, dtype=jnp.bfloat16)(jnp.tile(indices % 8, (x_t.shape[0], 1)))\n        \n        x = x + rank_emb + file_emb\n        x = nn.Dense(D_MODEL, dtype=jnp.bfloat16)(x) \n        \n        t_emb = nn.Embed(TIMESTEPS, D_MODEL, dtype=jnp.bfloat16)(t)\n        Block = nn.remat(UniMambaBlock)\n            \n        for _ in range(4): \n            x = Block(D_MODEL, N_STATE)(x, t_emb)\n            x = nn.gelu(x) \n            \n        if mask_dest is not None:\n            x = jnp.sum(x * mask_dest.astype(jnp.bfloat16), axis=1) \n            return nn.Dense(NUM_CLASSES, dtype=jnp.float32)(x)    \n            \n        return nn.Dense(NUM_CLASSES, dtype=jnp.float32)(x)\n\ninference_model = UniMambaChessEngine()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.417669Z","iopub.execute_input":"2026-02-14T09:47:56.417879Z","iopub.status.idle":"2026-02-14T09:47:56.427654Z","shell.execute_reply.started":"2026-02-14T09:47:56.417863Z","shell.execute_reply":"2026-02-14T09:47:56.427079Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ==============================================================================\n# CELL 2: DENSE ALGEBRAIC KERNELS (100% XLA FUSION)\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport optax\nimport numpy as np\n\ndef board_to_tensor(board):\n    x = np.zeros(64, dtype=np.int32)\n    for i in range(64):\n        p = board.piece_at(i)\n        if p: x[i] = p.piece_type + (0 if p.color else 6)\n    return x\n\n@jax.jit\ndef calculate_mtm_energies(frozen_params, candidate_batch, dest_indices, piece_classes):\n    num_candidates = candidate_batch.shape[0]\n    \n    mask_dest = jax.nn.one_hot(dest_indices, 64, dtype=jnp.int32)\n    masked_batch = candidate_batch * (1 - mask_dest) + 13 * mask_dest\n    t_batch = jnp.full((num_candidates,), 1, dtype=jnp.int32)\n    \n    mask_dest_expanded = jnp.expand_dims(mask_dest, -1).astype(jnp.float32)\n    dest_logits = inference_model.apply(\n        {'params': frozen_params}, masked_batch, t_batch, mask_dest=mask_dest_expanded\n    )\n    \n    probs = jax.nn.softmax(dest_logits, axis=-1)\n    mask_piece = jax.nn.one_hot(piece_classes, 14, dtype=jnp.float32)\n    actual_piece_probs = jnp.sum(probs * mask_piece, axis=-1)\n    \n    return -jnp.log(actual_piece_probs + 1e-7), probs\n\n@jax.jit\ndef rl_mtm_train_step(state, masked_boards, dest_indices, target_classes):\n    def loss_fn(params):\n        num_samples = masked_boards.shape[0]\n        t_batch = jnp.full((num_samples,), 1, dtype=jnp.int32)\n        \n        mask_dest = jax.nn.one_hot(dest_indices, 64, dtype=jnp.float32)\n        mask_dest_expanded = jnp.expand_dims(mask_dest, -1)\n        \n        target_logits = inference_model.apply(\n            {'params': params}, masked_boards, t_batch, mask_dest=mask_dest_expanded\n        )\n        \n        target_one_hot = jax.nn.one_hot(target_classes, 14, dtype=jnp.float32)\n        log_probs = jax.nn.log_softmax(target_logits)\n        return -jnp.sum(target_one_hot * log_probs, axis=-1).mean()\n\n    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n    return state.apply_gradients(grads=grads), loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.428084Z","iopub.execute_input":"2026-02-14T09:47:56.428244Z","iopub.status.idle":"2026-02-14T09:47:56.440562Z","shell.execute_reply.started":"2026-02-14T09:47:56.428229Z","shell.execute_reply":"2026-02-14T09:47:56.439729Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ==============================================================================\n# 3. MCTS NODE STRUCTURE WITH ALPHA-BETA OVERRIDES\n# ==============================================================================\nclass MCTSNode:\n    def __init__(self, state, parent=None, move=None, prior=0.0):\n        self.state = state; self.parent = parent; self.move = move\n        self.prior = prior; self.visits = 0; self.value_sum = 0.0\n        self.children = {}; self.is_expanded = False\n        self.is_proven_win = False  # Alpha-Beta Pruning\n        self.is_proven_loss = False # Alpha-Beta Pruning\n        self.xray_probs = None; self.xray_piece = None\n        \n    @property\n    def q_value(self):\n        if self.is_proven_win: return 1.0\n        if self.is_proven_loss: return -1.0\n        return self.value_sum / self.visits if self.visits > 0 else 0.0\n\n    def ucb(self, c_puct):\n        if self.is_proven_win: return float('inf')\n        if self.is_proven_loss: return -float('inf')\n        return self.q_value + c_puct * self.prior * (math.sqrt(self.parent.visits) / (1 + self.visits))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.440963Z","iopub.execute_input":"2026-02-14T09:47:56.441126Z","iopub.status.idle":"2026-02-14T09:47:56.450213Z","shell.execute_reply.started":"2026-02-14T09:47:56.441111Z","shell.execute_reply":"2026-02-14T09:47:56.449492Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ==============================================================================\n# 4. THE OMNISCIENT DASHBOARD (UI VISUALIZER)\n# ==============================================================================\nPIECE_NAMES = [\"Empty\", \"W_P\", \"W_N\", \"W_B\", \"W_R\", \"W_Q\", \"W_K\", \n               \"B_P\", \"B_N\", \"B_B\", \"B_R\", \"B_Q\", \"B_K\", \"MASK\"]\n\ndef render_dashboard(root, board, phase_title, sim_status, loss_info=\"\"):\n    \"\"\"Builds an HTML/SVG interface exposing all underlying math.\"\"\"\n    children = sorted(root.children.values(), key=lambda c: c.visits, reverse=True)\n    fill, arrows = {}, []\n    \n    # Generate Heatmap & PV Arrows\n    if children:\n        total_visits = sum(c.visits for c in children) + 1e-5\n        for child in children:\n            opacity = int((child.visits / total_visits) * 255)\n            fill[child.move.to_square] = f\"#0055ff{opacity:02x}\" \n            \n        curr, depth = root, 0\n        while curr.children and depth < 4:\n            valid = [c for c in curr.children.values() if not c.is_proven_loss]\n            if not valid: break\n            best = max(valid, key=lambda c: c.visits)\n            arrows.append(chess.svg.Arrow(best.move.from_square, best.move.to_square, color=\"#28a745\"))\n            curr = best; depth += 1\n\n    board_svg = chess.svg.board(board, arrows=arrows, fill=fill, size=400, lastmove=board.peek() if board.move_stack else None)\n    \n    # Calculate Overall Eval\n    eval_score = ((children[0].q_value + 1) / 2 * 100) if children else 50.0\n    eval_color = \"green\" if eval_score > 55 else \"red\" if eval_score < 45 else \"black\"\n    \n    # HTML Assembly\n    html = f\"\"\"\n    <div style='display: flex; gap: 20px; font-family: sans-serif; max-width: 900px; margin: auto; padding: 10px; border: 1px solid #ddd; border-radius: 8px;'>\n        <div>{board_svg}</div>\n        <div style='flex-grow: 1;'>\n            <h2 style='margin-top: 0; color: #333;'>{phase_title}</h2>\n            <div style='background: #f8f9fa; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>\n                <b>Status:</b> {sim_status} <br>\n                <b>Engine Eval:</b> <span style='color: {eval_color}; font-weight: bold;'>{eval_score:.1f}% Win Probability</span>\n                {f\"<br><b>RL Update Loss:</b> {loss_info}\" if loss_info else \"\"}\n            </div>\n            <h4 style='border-bottom: 1px solid #ccc; padding-bottom: 5px;'>X-Ray Internal Monologue</h4>\n            <div style='max-height: 280px; overflow-y: auto; font-size: 13px;'>\n    \"\"\"\n    \n    # Detail the top 3 lines\n    for i, c in enumerate(children[:3]):\n        ab_flag = \"<span style='color: red; font-weight: bold;'>[FORCED LOSS PRUNED]</span>\" if c.is_proven_loss else \"\"\n        ab_flag = \"<span style='color: green; font-weight: bold;'>[FORCED WIN DETECTED]</span>\" if c.is_proven_win else ab_flag\n        \n        html += f\"<div style='margin-bottom: 12px; padding: 8px; border-left: 3px solid #0055ff; background: #fdfdfd;'>\"\n        html += f\"<b>Line {i+1}: {board.san(c.move)}</b> {ab_flag}<br>\"\n        html += f\"<span style='color: #666;'>Visits: {c.visits} | Q-Value: {c.q_value:.2f} | Mamba-2 Prior: {c.prior*100:.1f}%</span><br>\"\n        \n        # MTM Predictions for this move\n        if c.xray_probs is not None:\n            html += f\"<div style='margin-top: 4px; font-family: monospace; font-size: 11px; color: #444;'>\"\n            html += f\"<b>[MASK] Prediction (Target Sq):</b><br>\"\n            top_preds = np.argsort(c.xray_probs)[::-1][:2]\n            for idx in top_preds:\n                mark = \" &lt;-- Actual\" if idx == c.xray_piece else \"\"\n                html += f\"&nbsp;&nbsp;{PIECE_NAMES[idx]}: {c.xray_probs[idx]*100:.1f}%{mark}<br>\"\n            if c.xray_piece not in top_preds:\n                html += f\"&nbsp;&nbsp;... {PIECE_NAMES[c.xray_piece]}: {c.xray_probs[c.xray_piece]*100:.2f}% &lt;-- Actual<br>\"\n            html += \"</div>\"\n        html += \"</div>\"\n        \n    html += \"</div></div></div>\"\n    \n    clear_output(wait=True)\n    display(HTML(html))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.450719Z","iopub.execute_input":"2026-02-14T09:47:56.450871Z","iopub.status.idle":"2026-02-14T09:47:56.460270Z","shell.execute_reply.started":"2026-02-14T09:47:56.450856Z","shell.execute_reply":"2026-02-14T09:47:56.459518Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n# 5. CORE MCTS EXECUTION ALGORITHM\n# ==============================================================================\ndef run_mcts(root, params, num_simulations=100, phase_title=\"Engine Analysis\", visualize=False):\n    key = jax.random.PRNGKey(int(time.time()))\n    for i in range(num_simulations):\n        node = root\n        \n        # 1. Selection & Alpha-Beta Overrides\n        while node.is_expanded and node.children:\n            valid_children = [c for c in node.children.values() if not c.is_proven_loss]\n            if not valid_children:\n                node.is_proven_loss = True\n                break\n            node = max(valid_children, key=lambda c: c.ucb(c_puct=2.0))\n            \n        if node.is_proven_loss or node.is_proven_win: \n            continue\n            \n        # 2. Expansion (TPU Deterministic MTM)\n        if not node.state.is_game_over():\n            moves = list(node.state.legal_moves)\n            candidates, dest_indices, piece_classes = [], [], []\n            \n            for m in moves:\n                node.state.push(m)\n                candidates.append(board_to_tensor(node.state))\n                dest_indices.append(m.to_square)\n                p = node.state.piece_at(m.to_square)\n                piece_classes.append(p.piece_type + (0 if p.color else 6))\n                node.state.pop()\n                \n            if candidates:\n                # TPU Call\n                energies, full_probs = calculate_mtm_energies(\n                    params, jnp.array(candidates), jnp.array(dest_indices, dtype=jnp.int32), jnp.array(piece_classes, dtype=jnp.int32)\n                )\n                energies, full_probs = np.array(energies), np.array(full_probs)\n                \n                # Temperature sharpening\n                priors = np.exp(-energies / 0.5)\n                priors /= np.sum(priors)\n                \n                # Tree instantiation\n                for idx, (m, p) in enumerate(zip(moves, priors)):\n                    new_board = node.state.copy()\n                    new_board.push(m)\n                    child_node = MCTSNode(new_board, parent=node, move=m, prior=p)\n                    child_node.xray_probs = full_probs[idx]\n                    child_node.xray_piece = piece_classes[idx]\n                    node.children[m] = child_node\n                    \n                # Inside run_mcts expansion block:\n                node.is_expanded = True\n                \n                # THE MATHEMATICAL FIX: V(S) = 2 * exp(-E) - 1\n                # We find the candidate move that maximizes this bounded value\n                value = float(np.max(2.0 * np.exp(-energies) - 1.0))\n            else: \n                value = 0.0\n        else:\n            outcome = node.state.outcome()\n            if outcome.winner is not None:\n                value = 1.0 if outcome.winner == node.state.turn else -1.0\n                if value == 1.0: node.is_proven_win = True\n                else: node.is_proven_loss = True\n            else: value = 0.0\n            \n        # 3. Minimax Backpropagation\n        curr = node\n        while curr.parent:\n            curr.visits += 1\n            curr.value_sum += value\n            value = -value \n            if curr.is_proven_win: curr.parent.is_proven_loss = True\n            curr = curr.parent\n        root.visits += 1\n        \n        # UI Hook (Render during search)\n        if visualize and i % 10 == 0:\n            render_dashboard(root, root.state, phase_title, f\"Simulating {i}/{num_simulations}...\")\n            \n    if visualize:\n        render_dashboard(root, root.state, phase_title, \"Analysis Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.460654Z","iopub.execute_input":"2026-02-14T09:47:56.460799Z","iopub.status.idle":"2026-02-14T09:47:56.470172Z","shell.execute_reply.started":"2026-02-14T09:47:56.460784Z","shell.execute_reply":"2026-02-14T09:47:56.469474Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ==============================================================================\n# CELL 6: MASSIVELY PARALLEL RLHF PRE-TRAINING (TRACKING & VISUALIZATION)\n# ==============================================================================\nimport time\nimport numpy as np\nimport jax.numpy as jnp\nimport jax\nimport chess\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt \n\nNUM_PARALLEL_GAMES = 128\nSIMS_PER_MOVE = 30\n\n# DECOUPLED MEMORY BOUNDS (Mathematically derived for 16GB HBM)\nMAX_INFERENCE_BATCH = 512  # Forward pass is O(B*D*N) -> Safe to push high\nMAX_TRAIN_BATCH = 128      # Backward pass is O(L*B*D*N) -> Must be constrained\n\ndef batched_self_play_rlhf(train_state_obj, num_epochs=5, visualize_game=True):\n    \"\"\"Executes 128 games concurrently with live UI visualization and hardware tracking.\"\"\"\n    print(f\"--- üöÄ INITIATING {NUM_PARALLEL_GAMES} PARALLEL RLHF GAMES ---\")\n    \n    # --------------------------------------------------------------------------\n    # 1. HARDWARE PROFILING (AOT COMPILATION CHECK)\n    # --------------------------------------------------------------------------\n    print(f\"\\n[Hardware] Compiling JIT Train Step (Batch Size: {MAX_TRAIN_BATCH}) and profiling memory bounds...\")\n    dummy_boards = jnp.zeros((MAX_TRAIN_BATCH, 64), dtype=jnp.int32)\n    dummy_dests = jnp.zeros((MAX_TRAIN_BATCH,), dtype=jnp.int32)\n    dummy_targets = jnp.zeros((MAX_TRAIN_BATCH,), dtype=jnp.int32)\n    \n    compiled_train_step = rl_mtm_train_step.lower(\n        train_state_obj, dummy_boards, dummy_dests, dummy_targets\n    ).compile()\n    \n    mem_profile = compiled_train_step.memory_analysis()\n    temp_mem_mb = mem_profile.temp_size_in_bytes / (1024**2)\n    \n    print(f\"[Hardware] TPU Backward Pass Temp Allocation: {temp_mem_mb:.2f} MB\")\n    if temp_mem_mb < 8000.0: # ~8GB is extremely safe for a 16GB TPU\n        print(\"[Hardware] ‚úÖ Safe BPTT Memory Pinning Successful.\")\n    else:\n        print(\"[Hardware] ‚ö†Ô∏è WARNING: Elevated HBM spillage detected in backward pass.\")\n        \n    print(\"\\n[Hardware] Warming up MXU registers...\\n\")\n    _ = rl_mtm_train_step(train_state_obj, dummy_boards, dummy_dests, dummy_targets)\n    jax.block_until_ready(_)\n    time.sleep(1) \n\n    # --------------------------------------------------------------------------\n    # 2. SOFTWARE & HARDWARE METRICS TRACKING\n    # --------------------------------------------------------------------------\n    history = {'loss': [], 'sps': [], 'epoch_time': []}\n    \n    for epoch in range(num_epochs):\n        start_time = time.time()\n        \n        boards = [chess.Board() for _ in range(NUM_PARALLEL_GAMES)]\n        roots = [MCTSNode(b.copy()) for b in boards]\n        game_histories = [[] for _ in range(NUM_PARALLEL_GAMES)]\n        active_games = set(range(NUM_PARALLEL_GAMES))\n        \n        move_number = 1\n        total_forward_passes = 0\n        forward_pass_time = 0.0\n        \n        while active_games and move_number < 80:\n            # --- LIVE VISUALIZATION (Watching Game 0) ---\n            if visualize_game and 0 in active_games and (move_number % 2 == 1):\n                render_dashboard(\n                    roots[0], boards[0], \n                    f\"Self-Play Epoch {epoch+1} | Move {move_number}\", \n                    f\"Active Games: {len(active_games)} | Simulating Engine Lines...\"\n                )\n            elif not visualize_game:\n                print(f\"Epoch {epoch+1} | Move {move_number} | Active Games: {len(active_games)}...\", end=\"\\r\")\n            \n            for sim in range(SIMS_PER_MOVE):\n                batch_candidates, batch_dest, batch_pieces, ptrs = [], [], [], []\n                \n                # A. Vectorized Selection\n                for i in active_games:\n                    node = roots[i]\n                    while node.is_expanded and node.children:\n                        valid = [c for c in node.children.values() if not c.is_proven_loss]\n                        if not valid: \n                            node.is_proven_loss = True\n                            break\n                        node = max(valid, key=lambda c: c.ucb(c_puct=2.0))\n                        \n                    if node.is_proven_loss or node.is_proven_win or node.state.is_game_over():\n                        continue\n                        \n                    for m in node.state.legal_moves:\n                        node.state.push(m)\n                        batch_candidates.append(board_to_tensor(node.state))\n                        batch_dest.append(m.to_square)\n                        p = node.state.piece_at(m.to_square)\n                        batch_pieces.append(p.piece_type + (0 if p.color else 6))\n                        node.state.pop()\n                        \n                    ptrs.append((i, node, len(list(node.state.legal_moves))))\n                \n                # B. TPU Acceleration (Using INFERENCE micro-batch size)\n                if batch_candidates:\n                    total_evals = len(batch_candidates)\n                    all_energies, all_probs = [], []\n                    \n                    t0 = time.time() \n                    for chunk_idx in range(0, total_evals, MAX_INFERENCE_BATCH):\n                        chunk_end = min(chunk_idx + MAX_INFERENCE_BATCH, total_evals)\n                        \n                        c_chunk = jnp.array(batch_candidates[chunk_idx:chunk_end])\n                        d_chunk = jnp.array(batch_dest[chunk_idx:chunk_end], dtype=jnp.int32)\n                        p_chunk = jnp.array(batch_pieces[chunk_idx:chunk_end], dtype=jnp.int32)\n                        \n                        e_chunk, prob_chunk = calculate_mtm_energies(\n                            train_state_obj.params, c_chunk, d_chunk, p_chunk\n                        )\n                        jax.block_until_ready(e_chunk)\n                        \n                        all_energies.append(np.array(e_chunk))\n                        all_probs.append(np.array(prob_chunk))\n                        \n                    forward_pass_time += (time.time() - t0)\n                    total_forward_passes += total_evals\n                    \n                    energies = np.concatenate(all_energies, axis=0)\n                    full_probs = np.concatenate(all_probs, axis=0)\n                    \n                    # C. Vectorized Expansion\n                    idx_offset = 0\n                    for (game_id, node, num_moves) in ptrs:\n                        node_energies = energies[idx_offset : idx_offset + num_moves]\n                        node_probs = full_probs[idx_offset : idx_offset + num_moves]\n                        idx_offset += num_moves\n                        \n                        priors = np.exp(-node_energies / 0.5)\n                        priors /= np.sum(priors)\n                        \n                        for move_idx, m in enumerate(node.state.legal_moves):\n                            new_board = node.state.copy()\n                            new_board.push(m)\n                            child = MCTSNode(new_board, parent=node, move=m, prior=priors[move_idx])\n                            child.xray_probs = node_probs[move_idx]\n                            \n                            p_type = new_board.piece_at(m.to_square)\n                            child.xray_piece = p_type.piece_type + (0 if p_type.color else 6)\n                            node.children[m] = child\n                            \n                        node.is_expanded = True\n                        value = float(np.max(2.0 * np.exp(-node_energies) - 1.0))\n                        \n                        curr = node\n                        while curr.parent:\n                            curr.visits += 1\n                            curr.value_sum += value\n                            value = -value \n                            if curr.is_proven_win: curr.parent.is_proven_loss = True\n                            curr = curr.parent\n                        roots[game_id].visits += 1\n\n            # D. Advance All Boards\n            finished = []\n            for i in active_games:\n                b, root = boards[i], roots[i]\n                valid = [c for c in root.children.values() if not c.is_proven_loss]\n                if not valid:\n                    finished.append(i)\n                    continue\n                    \n                best_node = max(valid, key=lambda c: c.visits)\n                \n                m_board = board_to_tensor(best_node.state).copy()\n                m_board[best_node.move.to_square] = 13\n                game_histories[i].append((m_board, best_node.move.to_square, best_node.xray_piece, b.turn))\n                \n                b.push(best_node.move)\n                roots[i] = best_node\n                roots[i].parent = None\n                \n                if b.is_game_over(): finished.append(i)\n                    \n            for i in finished: active_games.remove(i)\n            move_number += 1\n            \n        # E. Expert Iteration Gradient Update (Using TRAIN micro-batch size)\n        opt_data = []\n        for i, b in enumerate(boards):\n            out = b.outcome()\n            if out and out.winner is not None:\n                opt_data.extend([d for d in game_histories[i] if d[3] == out.winner])\n                \n        if opt_data:\n            m_b, d_i, t_c = map(jnp.array, zip(*[(d[0], d[1], d[2]) for d in opt_data]))\n            losses = []\n            \n            for b_start in range(0, len(opt_data), MAX_TRAIN_BATCH):\n                b_end = min(b_start + MAX_TRAIN_BATCH, len(opt_data))\n                train_state_obj, loss = rl_mtm_train_step(\n                    train_state_obj, \n                    m_b[b_start:b_end], \n                    d_i[b_start:b_end], \n                    t_c[b_start:b_end]\n                )\n                jax.block_until_ready(train_state_obj.params)\n                losses.append(loss)\n                \n            duration = time.time() - start_time\n            avg_loss = float(np.mean(losses))\n            sps = total_forward_passes / forward_pass_time if forward_pass_time > 0 else 0\n            \n            history['loss'].append(avg_loss)\n            history['sps'].append(sps)\n            history['epoch_time'].append(duration)\n            \n            if not visualize_game:\n                print(f\"\\nEpoch {epoch+1} Completed in {duration:.1f}s | RLHF Loss: {avg_loss:.4f} | Throughput: {sps:,.0f} SPS\\n\")\n            else:\n                render_dashboard(\n                    roots[0], boards[0], \n                    f\"Epoch {epoch+1} Completed\", \n                    f\"Trained on {len(opt_data)} optimums | Throughput: {sps:,.0f} SPS\",\n                    loss_info=f\"{avg_loss:.4f}\"\n                )\n                time.sleep(2) \n            \n    return train_state_obj, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.470628Z","iopub.execute_input":"2026-02-14T09:47:56.470776Z","iopub.status.idle":"2026-02-14T09:47:56.763808Z","shell.execute_reply.started":"2026-02-14T09:47:56.470763Z","shell.execute_reply":"2026-02-14T09:47:56.762943Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ==============================================================================\n# CELL 7: EXECUTION & LAUNCH\n# ==============================================================================\nimport jax\nimport jax.numpy as jnp\nimport optax\nfrom flax.training import train_state\nimport chess\nimport time\nimport matplotlib.pyplot as plt\n\n# --- 1. DEFINE INTERACTIVE GAME LOOP ---\ndef play_interactive(params):\n    \"\"\"Launches the Human vs Mamba-2 Match with the Omniscient Dashboard.\"\"\"\n    board = chess.Board()\n    root = MCTSNode(board.copy())\n\n    while not board.is_game_over():\n        if board.turn == chess.WHITE:\n            render_dashboard(root, board, \"Interactive Match\", \"Waiting for Human Input...\")\n            while True:\n                try:\n                    move_input = input(\"Your Move (e.g., e4, Nf3): \")\n                    if move_input.lower() in [\"quit\", \"exit\", \"resign\"]:\n                        print(\"Game Aborted.\")\n                        return\n                    move = board.push_san(move_input)\n                    if move in root.children:\n                        root = root.children[move]\n                        root.parent = None \n                    else:\n                        root = MCTSNode(board.copy())\n                    break\n                except ValueError:\n                    print(\"Invalid move format. Please use Standard Algebraic Notation (e.g., e4).\")\n        else:\n            run_mcts(root, params, num_simulations=60, phase_title=\"Interactive Match\", visualize=True)\n            valid_children = [c for c in root.children.values() if not c.is_proven_loss]\n            if not valid_children:\n                print(\"Mamba-2 Resigns.\")\n                break\n            best_node = max(valid_children, key=lambda c: c.visits)\n            board.push(best_node.move)\n            root = best_node\n            root.parent = None\n\n    render_dashboard(root, board, \"Match Finished\", f\"Result: {board.result()}\")\n    print(\"Game Over\")\n\n# --- 2. STATE INITIALIZATION ---\ntry:\n    _ = master_state.params\n    print(\"‚úÖ Loaded existing TrainState with trained weights.\")\nexcept NameError:\n    print(\"‚ö†Ô∏è No existing weights found. Initializing fresh Uni-Mamba model...\")\n    key = jax.random.PRNGKey(42)\n    dummy_x = jnp.zeros((1, 64), dtype=jnp.int32)\n    dummy_t = jnp.zeros((1,), dtype=jnp.int32)\n    params = inference_model.init(key, dummy_x, dummy_t)['params']\n    \n    master_state = train_state.TrainState.create(\n        apply_fn=inference_model.apply, \n        params=params, \n        tx=optax.adamw(learning_rate=3e-4)\n    )\n    print(\"‚úÖ Model initialized.\")\n\n# --- 3. MISSION CONTROL ---\n\n# [MODE A] MASSIVELY PARALLEL PRE-TRAINING\n# By setting visualize_game=True, the engine will render the ongoing self-play matches\nmaster_state, metrics = batched_self_play_rlhf(master_state, num_epochs=10, visualize_game=True)\n\n# Visualize Hardware & Software Learning Curves\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(metrics['loss'], marker='o', color='red')\nplt.title('RLHF Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Cross-Entropy Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(metrics['sps'], marker='o', color='blue')\nplt.title('Hardware Throughput (SPS)')\nplt.xlabel('Epoch')\nplt.ylabel('Steps Per Second')\nplt.tight_layout()\nplt.show()\n\n# [MODE B] INTERACTIVE PLAY (Uncomment to play against the updated weights)\nplay_interactive(master_state.params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:47:56.764400Z","iopub.execute_input":"2026-02-14T09:47:56.764640Z","iopub.status.idle":"2026-02-14T09:56:35.849501Z","shell.execute_reply.started":"2026-02-14T09:47:56.764623Z","shell.execute_reply":"2026-02-14T09:56:35.848194Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style='display: flex; gap: 20px; font-family: sans-serif; max-width: 900px; margin: auto; padding: 10px; border: 1px solid #ddd; border-radius: 8px;'>\n        <div><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"400\" height=\"400\"><desc><pre>r n b . k b n r\np p p N . p p p\n. . . . p . . .\n. . q . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.027450980392156862\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.027450980392156862\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.027450980392156862\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.027450980392156862\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.027450980392156862\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove c5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.4980392156862745\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.30980392156862746\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark lastmove d6\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"#0055ff\" opacity=\"0.0\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(105, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /><line x1=\"172.5\" y1=\"82.5\" x2=\"200.3940799721266\" y2=\"138.2881599442532\" stroke=\"#28a745\" stroke-width=\"9.0\" stroke-linecap=\"butt\" class=\"arrow\" /><polygon points=\"215.4875388202502,168.4750776405004 215.4875388202502,130.74143052019141 185.30062112400302,145.834889368315\" fill=\"#28a745\" class=\"arrow\" /><line x1=\"127.5\" y1=\"172.5\" x2=\"145.45316561961457\" y2=\"154.54683438038543\" stroke=\"#28a745\" stroke-width=\"9.0\" stroke-linecap=\"butt\" class=\"arrow\" /><polygon points=\"169.31801948466054,130.68198051533946 133.52073868709158,142.61440744786245 157.38559255213755,166.47926131290842\" fill=\"#28a745\" class=\"arrow\" /><line x1=\"217.5\" y1=\"172.5\" x2=\"245.3940799721266\" y2=\"116.71184005574679\" stroke=\"#28a745\" stroke-width=\"9.0\" stroke-linecap=\"butt\" class=\"arrow\" /><polygon points=\"260.48753882025017,86.52492235949963 230.30062112400302,109.165110631685 260.48753882025017,124.25856947980859\" fill=\"#28a745\" class=\"arrow\" /><line x1=\"307.5\" y1=\"37.5\" x2=\"251.7118400557468\" y2=\"65.3940799721266\" stroke=\"#28a745\" stroke-width=\"9.0\" stroke-linecap=\"butt\" class=\"arrow\" /><polygon points=\"221.5249223594996,80.4875388202502 259.25856947980856,80.48753882025018 244.165110631685,50.30062112400302\" fill=\"#28a745\" class=\"arrow\" /></svg></div>\n        <div style='flex-grow: 1;'>\n            <h2 style='margin-top: 0; color: #333;'>Self-Play Epoch 1 | Move 27</h2>\n            <div style='background: #f8f9fa; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>\n                <b>Status:</b> Active Games: 128 | Simulating Engine Lines... <br>\n                <b>Engine Eval:</b> <span style='color: black; font-weight: bold;'>47.8% Win Probability</span>\n                \n            </div>\n            <h4 style='border-bottom: 1px solid #ccc; padding-bottom: 5px;'>X-Ray Internal Monologue</h4>\n            <div style='max-height: 280px; overflow-y: auto; font-size: 13px;'>\n    <div style='margin-bottom: 12px; padding: 8px; border-left: 3px solid #0055ff; background: #fdfdfd;'><b>Line 1: Ne5</b> <br><span style='color: #666;'>Visits: 16 | Q-Value: -0.04 | Mamba-2 Prior: 39.0%</span><br><div style='margin-top: 4px; font-family: monospace; font-size: 11px; color: #444;'><b>[MASK] Prediction (Target Sq):</b><br>&nbsp;&nbsp;W_N: 34.4% &lt;-- Actual<br>&nbsp;&nbsp;W_P: 11.8%<br></div></div><div style='margin-bottom: 12px; padding: 8px; border-left: 3px solid #0055ff; background: #fdfdfd;'><b>Line 2: Nb6</b> <br><span style='color: #666;'>Visits: 10 | Q-Value: 0.11 | Mamba-2 Prior: 18.6%</span><br><div style='margin-top: 4px; font-family: monospace; font-size: 11px; color: #444;'><b>[MASK] Prediction (Target Sq):</b><br>&nbsp;&nbsp;W_N: 23.7% &lt;-- Actual<br>&nbsp;&nbsp;B_B: 16.4%<br></div></div><div style='margin-bottom: 12px; padding: 8px; border-left: 3px solid #0055ff; background: #fdfdfd;'><b>Line 3: Rg1</b> <br><span style='color: #666;'>Visits: 1 | Q-Value: -0.72 | Mamba-2 Prior: 8.9%</span><br><div style='margin-top: 4px; font-family: monospace; font-size: 11px; color: #444;'><b>[MASK] Prediction (Target Sq):</b><br>&nbsp;&nbsp;W_R: 16.4% &lt;-- Actual<br>&nbsp;&nbsp;W_N: 11.6%<br></div></div></div></div></div>"},"metadata":{}},{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Model initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# --- 3. MISSION CONTROL ---\u001b[39;00m\n\u001b[32m     69\u001b[39m \n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# [MODE A] MASSIVELY PARALLEL PRE-TRAINING\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# By setting visualize_game=True, the engine will render the ongoing self-play matches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m master_state, metrics = \u001b[43mbatched_self_play_rlhf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize_game\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Visualize Hardware & Software Learning Curves\u001b[39;00m\n\u001b[32m     75\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mbatched_self_play_rlhf\u001b[39m\u001b[34m(train_state_obj, num_epochs, visualize_game)\u001b[39m\n\u001b[32m    138\u001b[39m priors /= np.sum(priors)\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m move_idx, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(node.state.legal_moves):\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     new_board = \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     new_board.push(m)\n\u001b[32m    143\u001b[39m     child = MCTSNode(new_board, parent=node, move=m, prior=priors[move_idx])\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/chess/__init__.py:3877\u001b[39m, in \u001b[36mBoard.copy\u001b[39m\u001b[34m(self, stack)\u001b[39m\n\u001b[32m   3875\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack:\n\u001b[32m   3876\u001b[39m     stack = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.move_stack) \u001b[38;5;28;01mif\u001b[39;00m stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m stack\n\u001b[32m-> \u001b[39m\u001b[32m3877\u001b[39m     board.move_stack = [\u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmove\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.move_stack[-stack:]]\n\u001b[32m   3878\u001b[39m     board._stack = \u001b[38;5;28mself\u001b[39m._stack[-stack:]\n\u001b[32m   3880\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m board\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/copy.py:97\u001b[39m, in \u001b[36mcopy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rv, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/copy.py:247\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# aha, this is the first one :-)\u001b[39;00m\n\u001b[32m    245\u001b[39m         memo[\u001b[38;5;28mid\u001b[39m(memo)]=[x]\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reconstruct\u001b[39m(x, memo, func, args,\n\u001b[32m    248\u001b[39m                  state=\u001b[38;5;28;01mNone\u001b[39;00m, listiter=\u001b[38;5;28;01mNone\u001b[39;00m, dictiter=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    249\u001b[39m                  *, deepcopy=deepcopy):\n\u001b[32m    250\u001b[39m     deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n","\u001b[31mKeyboardInterrupt\u001b[39m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9}]}